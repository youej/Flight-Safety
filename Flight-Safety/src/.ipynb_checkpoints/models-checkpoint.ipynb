{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9242a83-574c-4689-b3b2-e642f8f73485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 20:04:21.982857: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import GRU, Dense, TimeDistributed, Lambda, Flatten, Dropout, Conv1D, BatchNormalization, ReLU, MaxPooling1D\n",
    "from keras.layers import Input, Reshape, concatenate\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2d2ec2a-2f99-4e6b-a15b-acaf58537c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseGRU:\n",
    "    def __init__(self, input_shape, learning_rate, dropout, recurrent_dropout, \n",
    "                 kernel_regularizer, recurrent_regularizer):\n",
    "        self.input_shape = input_shape\n",
    "        self.learning_rate = learning_rate\n",
    "        self.dropout = dropout\n",
    "        self.recurrent_dropout = recurrent_dropout\n",
    "        self.kernel_regularizer = kernel_regularizer\n",
    "        self.recurrent_regularizer = recurrent_regularizer\n",
    "        self.model = self.create_model()\n",
    "\n",
    "    def create_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(GRU(20, dropout=self.dropout, recurrent_dropout=self.recurrent_dropout, return_sequences=True, input_shape=self.input_shape, \n",
    "                      kernel_regularizer=self.kernel_regularizer, recurrent_regularizer=self.recurrent_regularizer))\n",
    "        model.add(TimeDistributed(Dense(500, activation='tanh', kernel_regularizer=self.kernel_regularizer)))\n",
    "        model.add(TimeDistributed(Dense(1, activation='sigmoid', kernel_regularizer=self.kernel_regularizer)))\n",
    "        model.add(Flatten())\n",
    "\n",
    "        # Custom MIL aggregation layer using max functions\n",
    "        def mil_aggregation(x):\n",
    "            return K.max(x, axis=1, keepdims=True)\n",
    "\n",
    "        model.add(Lambda(mil_aggregation))\n",
    "        model.compile(optimizer=Adam(learning_rate=self.learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def summary(self):\n",
    "        return self.model.summary()\n",
    "\n",
    "    def fit(self, x, y, epochs=10, batch_size=32, validation_data=None):\n",
    "        return self.model.fit(x, y, epochs=epochs, batch_size=batch_size, validation_data=validation_data)\n",
    "\n",
    "    def evaluate(self, x, y):\n",
    "        return self.model.evaluate(x, y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)\n",
    "\n",
    "    def save(self, filepath):\n",
    "        self.model.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0054d0f3-9140-48e9-8e1a-f939708f3484",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadCnnRnn:\n",
    "    def __init__(self, input_shape, kernel_sizes, filters, learning_rate, weight_decay, \n",
    "                 dropout, recurrent_dropout, kernel_regularizer, recurrent_regularizer):\n",
    "        self.input_shape = input_shape\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "        self.filters = filters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.dropout = dropout\n",
    "        self.recurrent_dropout = recurrent_dropout\n",
    "        self.kernel_regularizer = kernel_regularizer\n",
    "        self.recurrent_regularizer = recurrent_regularizer\n",
    "        self.model = self.create_model()\n",
    "\n",
    "    def create_model(self):\n",
    "        input_layer = Input(shape=self.input_shape)\n",
    "\n",
    "        # Multi-Head CNN processing\n",
    "        cnn_outputs = []\n",
    "        print(f'Feature amount: {self.input_shape[1]}')\n",
    "        for i in range(self.input_shape[1]):\n",
    "            head = Reshape((self.input_shape[0], 1))(input_layer[:, :, i:i+1])\n",
    "            for j in range(len(self.kernel_sizes)):\n",
    "                head = Conv1D(filters=self.filters[j], kernel_size=self.kernel_sizes[j], activation='relu',\n",
    "                              kernel_regularizer=l2(self.weight_decay))(head)\n",
    "                head = BatchNormalization()(head)\n",
    "            head = Conv1D(filters=1, kernel_size=1, padding='same', activation='sigmoid',\n",
    "                          kernel_regularizer=l2(self.weight_decay))(head)\n",
    "            cnn_outputs.append(head)\n",
    "        concatenated = concatenate(cnn_outputs)\n",
    "        \n",
    "        # Sequential GRU processing from BaseGRU configuration\n",
    "        gru_layer = GRU(20, dropout=self.dropout, recurrent_dropout=self.recurrent_dropout,\n",
    "                        return_sequences=True, kernel_regularizer=self.kernel_regularizer,\n",
    "                        recurrent_regularizer=self.recurrent_regularizer)(concatenated)\n",
    "        time_distributed_dense = TimeDistributed(Dense(500, activation='tanh', kernel_regularizer=self.kernel_regularizer))(gru_layer)\n",
    "        time_distributed_output = TimeDistributed(Dense(1, activation='sigmoid', kernel_regularizer=self.kernel_regularizer))(time_distributed_dense)\n",
    "        flattened = Flatten()(time_distributed_output)\n",
    "        \n",
    "        # Custom MIL aggregation layer using max functions\n",
    "        def mil_aggregation(x):\n",
    "            return K.max(x, axis=1, keepdims=True)\n",
    "\n",
    "        mil_output = Lambda(mil_aggregation)(flattened)\n",
    "\n",
    "        # Compile the model\n",
    "        model = Model(inputs=input_layer, outputs=mil_output)\n",
    "        model.compile(optimizer=Adam(learning_rate=self.learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def summary(self):\n",
    "        return self.model.summary()\n",
    "\n",
    "    def fit(self, x, y, epochs=30, batch_size=128, validation_data=None):\n",
    "        return self.model.fit(x, y, epochs=epochs, batch_size=batch_size, validation_data=validation_data)\n",
    "\n",
    "    def evaluate(self, x, y):\n",
    "        return self.model.evaluate(x, y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)\n",
    "\n",
    "    def save(self, filepath):\n",
    "        self.model.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ce0d24-92bb-4b79-8dbe-0df603355bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
